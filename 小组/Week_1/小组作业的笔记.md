# 小组作业的笔记

哈喽哈喽，这次是来分析一下我这周做的小组作业的一个情况分析，仍在学习，还请见谅哈ヾ(≧▽≦*)o



### 一、Boston住宅数据集（线性回归）

​	本次作业来源于寒假训练营，虽然之前早已经做过，不过这一次也是让我再次练练手。本节将重点简述关于我的线性回归与sklearn线性回归的区别

#### 	区别：	

- **`	sklearn` 的线性回归**：
  - 它使用的是最小二乘），类似于用公式一步到位解决问题。
  - 支持更多的功能，比如：
    - 是否计算截距（`fit_intercept`）。
    - 是否对数据进行标准化（`normalize`）。
    - 支持并行计算（`n_jobs`），可以加快计算速度。
  - 代码更复杂，因为它考虑了很多边界情况和异常处理。
  - 比如它会检查输入数据是否合法，是否需要进行标准化等。
- 我的**线性回归**：
  - 你提供了两种方法：**梯度下降**和**最小二乘法**。
    - **梯度下降**：通过一步步调整参数来逼近最优解，适合数据量很大的情况。
    - **最小二乘法**：直接用数学公式求解，适合数据量小的情况。
  - 代码更简单，容易理解。
  - 没有处理很多边界情况，比如输入数据是否合法。

​	**接下来，我会调整好自己的代码，让自己的代码考虑更多的情况，完善代码情况，如检查输入数据是否合法，是否需要进行标准化等。**

### 二、Pima皮马印第安人糖尿病数据库（逻辑回归）:

​	在本次训练中，我学习到了有关逻辑回归的使用以及运用。逻辑回归属于二分类的范畴，他与线性回归有相同之处也有不同。

- 相同：
  - 他们的都是监督训练，自然都需要训练集，验证集，测试集
  - 他们都可以使用梯度下降来训练模型
  - 可以损失函数来判断模型的拟合程度

- 不同：
  - 线性回归的损失函数为**MSE**，逻辑回归为**交叉熵**
  - 并且逻辑回归最终的取值是只有0和1

​	总之他们的效果有共同之处，也有特别之点，好滴，现在我对AI更有好奇心了捏ο(=•ω＜=)ρ⌒☆