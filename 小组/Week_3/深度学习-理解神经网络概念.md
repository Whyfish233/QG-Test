# 深度学习-理解神经网络概念



## 概念

​	**深度学习**是机器学习的一个子领域，专注于使用多层神经网络来模拟人类大脑的学习和思维过程，深度学习是机器学习的一部分。

​	**人工神经网络**也简称为神经网络，是一种模仿动物神经网络行为特征，进行分布式并行信息处理的数学模型。这种网络依靠系统的复杂程度，通过调整内部大量节点之间相互连接的关系，从而达到处理信息的目的。

​	**BP神经网络**是一种具有能将误差反向传播至隐藏层的神经网络。



## BP神经网络

### BP神经网络的组成成分：

​	BP神经网络由 **输入层**、**隐藏层**（也称中间层）和 **输出层** 构成 ，其中隐含层有一层或者多层。每一层可以有若干个节点。层与层之间节点的连接状态通过 **权重** 来体现。

<img src="https://whywhyfish.oss-cn-guangzhou.aliyuncs.com/picture/4dc044d9a6ed79cdc513004e2b654122.png" alt="在这里插入图片描述" style="zoom: 67%;" />

#### 	感知机**——BP神经网络中的单个节点**

​	人眼睛的视网膜由排成矩阵的光传感元件组成，这些传感元件的输出连接到一些神经元。当输入达到一定水平或者有一定类型的输入产生时，神经元就给出输出。

​	所以我们可以将这个思路引入神经网络即当输入的活动超过一定的内部阈值时，神经元被激活，当输入具有一定的特点时，出发速率也增加。

<img src="https://whywhyfish.oss-cn-guangzhou.aliyuncs.com/picture/1ad8b1cfbef106772a65f91079230503.png" alt="在这里插入图片描述" style="zoom:67%;" />	

​	注：

* 由输入项、权重、偏置、激活函数、输出组成。

  

#### 	BP神经网络的基本运行思路

<img src="https://whywhyfish.oss-cn-guangzhou.aliyuncs.com/picture/image-20250407233604826.png" alt="image-20250407233604826" style="zoom:67%;" />

##### 		正向传播：

​		数据（信息、信号）从输入端输入后，沿着网络的指向，乘以对应的权重后再加和，再将结果作为输入在激活函数中计算，将计算的结果作为输入传递给下一个节点。依次计算，直到得到最终结果。

​		通过每一层的感知器，层层计算，得到输出，每个节点的输出作为下一个节点的输入。这个过程就是正向传播

​                                                        <img src="https://whywhyfish.oss-cn-guangzhou.aliyuncs.com/picture/2702a050394741a2061feacb9232c01d.png" alt="在这里插入图片描述" style="zoom:67%;" />		

##### 		反向传播

​		将输出的结果与期望的输出结果进行比较，将比较产生的误差利用网络进行反向传播，本质是一个“负反馈”的过程。
通过多次迭代，不断地对网络上的各个节点间的权重进行调整（更新），权重的调整（更新）采用梯度下降法。



##卷积神经网络（CNN）

我们为了后面学的AlexNet、ResNet、LSTM，得先提前掌握一点CNN的知识。

### 概念

​	我认为（简单的）：就是将一张图片/信息的特征提取浓缩。（没错，我觉得就是这样）

​	当然还得来个介绍引入：

​	在传统神经网络中，我们要识别下图红色框中的图像时，我们很可能识别不出来，因为这六张图的![img](https://whywhyfish.oss-cn-guangzhou.aliyuncs.com/picture/d871cc8ec807852aab00f6e1595dbdd2.png)位置都不通，计算机无法分辨出他们其实是一种形状或物体。（因为系统觉得你下面六张图有很多黄色点包围，那就认为不是我想找的图啦)

<img src="https://whywhyfish.oss-cn-guangzhou.aliyuncs.com/picture/image-20250408001132126.png" alt="image-20250408001132126" style="zoom:50%;" />

​	我们希望一个物体不管在画面左侧还是右侧，都会被识别为同一物体。卷积神经网络（CNN）等深度学习模型在卷积层中使用了卷积操作，这个操作可以捕捉到图像中的局部特征而不受其位置的影响。（通过提取特征，通过特征来判断）

#### 	基本原理

​	在卷积神经网络中，卷积操作是指将一个可移动的小窗口（红色小窗）与图像进行逐元素相乘然后相加的操作。这个小窗口其实是一组固定的权重，它可以被看作是一个特定的滤波器（filter）或**卷积核**。这个操作的名称“卷积”，源自于这种元素级相乘和求和的过程。

​	简而言之，**卷积操作就是用一个可移动的小窗口来提取图像中的特征**，这个小窗口包含了一组特定的权重，通过与图像的不同位置进行卷积操作

​	这张图中蓝色的框就是指一个数据窗口，红色框为卷积核（滤波器），最后得到的绿色方形就是卷积的结果（数据窗口中的数据与卷积核逐个元素相乘再求和）

​                                                         	<img src="https://whywhyfish.oss-cn-guangzhou.aliyuncs.com/picture/d0172774f7e42ae2f6310b63e59b4906.gif" alt="img" style="zoom:50%;" />

##### 		卷积需要注意哪些问题？

​		a.步长stride：每次滑动的位置步长。

​		b. 卷积核的个数：决定输出的depth厚度。同时代表卷积核的个数。

​		c. 填充值zero-padding：在外围边缘补充若干圈0，方便从初始位置以步长为单位可以刚好滑倒末尾位置，通俗地讲就是为了总		长能被步长整除。
