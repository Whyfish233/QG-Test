# 深度学习笔记

### 第一课：什么是机器学习？

#### 	**机器学习是一种通过算法解析数据、从中提取规律，并基于这些规律对新数据做出智能判断或预测的技术范式。**	

与传统编程中开发者需明确编写每一步执行逻辑不同，机器学习系统的核心在于其具备**自主从数据中学习**的能力。例如，当算法处理带有情感标签的媒体数据时，它会自动识别文本特征与情感倾向之间的潜在关联——可能发现"卓越""创新"等词汇常出现在正面报道中，而"缺陷""争议"等词汇多伴随负面评价。经过充分训练后，该系统无需人工定义关键词库，即可对新文章的情感倾向做出准确分类。

这种范式转变的关键在于：开发者不再需要将领域知识硬编码为具体规则，而是通过设计学习架构，让算法在数据驱动下自主发现特征与目标之间的映射关系。就像人类通过经验积累知识一样，机器学习模型通过迭代优化逐步提升其决策能力，这正是人工智能实现自主认知的核心机制。     





### 第二课：什么是深度学习？

#### 	深度学习是机器学习的一个子领域，它使用受大脑神经网络结构和功能启发的算法。

​		不过，我们在深度学习中使用的神经网络并不是真正的生物神经网络。它们只是与生物神经网络共享一些特征，因此，我们称它们为*人工*神经网络 （ANN）。

​		我们还经常使用其他术语来指代 ANN。在深度学习领域，术语*人工神经网络* （ANN） 可与以下内容互换使用：

- 

  - 神经网络

  - 型	

  * 网

​	

​	要理解深度学习中的*术语*，我们首先需要了解 ANN 的结构。一旦我们知道了这一点，我们就能够看到深度学习使用一种特定类型的 ANN，我们称之为深度网络或深度人工神经网络 神经网络。

1. 人工神经网络是使用我们所谓的神经元构建的。
2. ANN 中的神经元被组织成我们所说的层。
3. ANN *中的*图层（除输入和输出图层之外的所有图层）称为隐藏图层。
4. 如果 ANN 具有多个隐藏层，则称该 ANN 为深度 ANN。



### 第三课：什么是人工神经网络？

#### 人工神经网络是一种计算系统，它由一组称为神经元的连接单元组成，这些单元被组织成我们所说的层。

​	连接的神经单元形成所谓的网络。神经元之间的每个连接都会将信号从一个神经元传输到另一个神经元。接收神经元处理信号并将信号发送到网络内连接到它的下游神经元。注意 神经元通常也称为*节点*。

​	节点被组织成我们所说的层。在最高级别，每个 **人工神经网络** 中有三种类型的层：

- 

  - 输入层

  - 隐藏图层

  - 输出层

​	不同的层对其 Importing 执行不同类型的转换。数据从输入层开始流经网络，然后穿过隐藏层，直到到达输出层。这称为通过 网络。位于输入和输出图层之间的图层称为隐藏图层。

**放个图片，不过我得搞会图床先**

<img src="https://whywhyfish.oss-cn-guangzhou.aliyuncs.com/picture/image-20250325151640259.png" alt="image-20250325151640259" style="zoom: 50%;" />

#### Keras 顺序模型（线性）（利用Keras来尝试搞一个人工神经网络）

​	在 Keras 中，我们可以构建所谓的 Sequential 模型。Keras 将 Sequential 模型定义为线性层的 SequenceStack 。这就是我们可能预料到的，因为我们刚刚了解到神经元被组织成层。

​	这个顺序模型是 Keras 对人工神经网络的实现。现在让我们看看如何使用 Keras 构建一个非常简单的 sequential 模型。

首先，我们导入所需的 Keras 类。

```python
from keras.models import Sequential
from keras.layers import Dense, Activation
```

然后，我们创建一个名为 的变量，并将其设置为等于对象的实例。`model``Sequential`

```python
model = Sequential(layers)
```

对于构造函数，我们传递一个对象数组。这些对象中的每一个实际上都是层。`Dense``Dense`

```python
layers = [
    Dense(units=3, input_shape=(2,), activation='relu'),#有3个神经元，作为隐藏层。同时有两个																					输入节点
    Dense(units=2, activation='softmax')#有两个神经元，作为输出节点
]
```

单词 *dense* 表示这些图层的类型 。*dense*是一种特殊类型的层，但随着我们继续深度学习之旅，我们将看到许多其他类型。`Dense`

现在，只需了解 dense 是 人工神经网络 中最基本的层类型，并且 dense 层的每个输出都是使用该层的每个输入计算的。

查看我们图像中（在上一节中）从隐藏层到输出层的箭头，我们可以看到隐藏层中的每个节点都连接到输出层中的所有节点。这就是我们如何知道图像中的输出层 是密集层。同样的 logic 也适用于 hidden layer。

传递给每个层中 layer 构造函数的第一个参数告诉我们它应该有多少个神经元。`Dense`

input shape 参数告诉我们输入层有多少个神经元，所以在我们的例子中，我们有两个。`input_shape=(2,)`



### 第四课：什么是神经网络的层？

​	我们在上一课程，学过了关于*dense*（密集层），当然也有其他的图床类型

* 

  	* Dense layer **（全连接层） **  :完全连接每个输入 添加到其层中的每个输出中。

   * Convolutional layer  **（卷积层）**:通常用于处理图像数据的模型

   * Pooling layer  **（池化层）**:用于处理时间序列数据的模型

   * Recurrent layer  **（循环层）**

   * Normalization layer  **(归一化层）**

     

#### 	示例人工神经网络：

<img src="https://whywhyfish.oss-cn-guangzhou.aliyuncs.com/picture/image-20250325154058607.png" alt="image-20250325154058607" style="zoom:50%;" />

我们可以看到，第一层，即输入层，由八个节点组成。该层中的 8 个节点都代表数据集中给定样本中的单个特征。

这告诉我们数据集中的单个样本由 8 个维度组成。当我们从数据集中选择一个样本并将该样本传递给模型时，样本中包含的八个值中的每一个都将提供给 输入层。

我们可以看到，八个 input 节点中的每一个都连接到下一层中的每个节点。

第一层和第二层之间的每个连接都将前一个节点的输出传输到接收节点的输入（从左到右）。中间的两个层各有六个节点，它们是隐藏层，因为它们被定位 在输入和输出层之间。

#### 图层权重

两个节点之间的每个连接都有一个关联的权重，它只是一个数字。

每个权重表示两个节点之间的连接强度。当网络在输入层的给定节点收到输入时，此输入将通过连接传递到下一个节点，并且输入将乘以权重 分配给该连接。

然后，对于第二层中的每个节点，将计算每个**传入连接的加权和**。然后，此 sum 将传递给激活函数，该函数对给定的 sum 执行某种类型的转换。例如，激活函数 可以将总和转换为介于 0 和 1 之间的数字。实际的转换将根据使用的激活函数而有所不同。

​                                                              **节点输出 = 激活（输入的加权和）**

#### 通过神经网络的前向传播

一旦我们获得给定节点的输出，获得的输出就是作为输入传递给下一层中的节点的值。

此过程一直持续到到达输出层。输出层中的节点数取决于我们拥有的可能的输出或预测类的数量。在我们的示例中，我们有四个可能的预测类。

假设我们的模型的任务是对四种类型的动物进行分类。输出层中的每个节点都表示四种可能性之一。例如，我们可以有猫、狗、美洲驼或蜥蜴。类别或类取决于有多少类 在我们的数据集中。

对于数据集中的给定样本，从输入层到输出层的整个过程称为通过网络的正向传递。

#### 查找最佳权重（Keras实现）

在之前的讨论中，我们了解了如何使用 Keras 构建顺序模型。现在，让我们对我们的示例网络执行此作。

首先定义一个对象列表，即我们的图层。然后，此列表将传递给 sequential 模型的构造函数。

于是，我们构造这样的网络：

```python
layers = [
    Dense(units=6, input_shape=(8,), activation='relu'),
    Dense(units=6, activation='relu'),
    Dense(units=4, activation='softmax')
]
```

在上述代码，我们构造了8个输入节点，第一个隐藏层有6个节点，第二个隐藏层有6个隐藏层，4个输出节点。

记住：隐藏层使用“relu”函数；输出层使用“softmax”

最终我们可以写为：

```python
from keras.models import Sequential
from keras.layers import Dense, Activation

layers = [
    Dense(units=6, input_shape=(8,), activation='relu'),
    Dense(units=6, activation='relu'),
    Dense(units=4, activation='softmax')
]

model = Sequential(layers)
```

注：<img src="C:\Users\为什么捉妖\AppData\Roaming\Typora\typora-user-images\image-20250325160115945.png" alt="image-20250325160115945" style="zoom:33%;" />

这个是啥呀呀呀！！！，问学长



### 第五课：神经网络中的激活函数

​	在本章中，我们会了解什么叫激活函数，并在神经网络该怎么用。

#### 什么是激活函数？

​                              **在人工神经网络中，激活函数是将节点的输入映射到其相应输出的函数。**

### 激活函数有什么作用？

​	我们先看一些示例的激活函数

#### 	**Sigmoid激活函数**

Sigmoid 接收输入并执行以下作：

- 对于大多数负输入，sigmoid 会将输入转换为非常接近的数字0.
- 对于大多数正输入，sigmoid 会将输入转换为非常接近1.
- 对于相对接近0，sigmoid 会将输入转换为0和1.

<img src="https://whywhyfish.oss-cn-guangzhou.aliyuncs.com/picture/image-20250325160606935.png" alt="image-20250325160606935" style="zoom:50%;" />

对于 sigmoid，0是下限，而1是上限。

#### 	Relu 激活函数

​	我们的激活函数并不总是将值分为1或0

​	接下来的*Relu*函数有所不同，函数如下

![image-20250325220630973](https://whywhyfish.oss-cn-guangzhou.aliyuncs.com/picture/image-20250325220630973.png)

​	因此，如果输入小于或等于0，则 relu 将输出0.如果输入大于0，relu 将只输出给定的输入。

​	公式如下：

```python
// pseudocode
function relu(x) {
    if (x <= 0) {
        return 0;
    } else {
        return x;
    }
}
```

### 	我们为什么要使用激活函数？

​	原因是，我们发现单纯用线性函数，不足以拟合我们想要的函数，即深度神经网络学习的映射类型比简单的线性映射更复杂。

​	**具有非线性激活函数使我们的神经网络能够计算任意复杂的函数。**

#### 	

#### 	如何证明Relu函数为非线性函数？

​	我们知道一般的线性函数需要满足以下形式：

​	

<img src="https://whywhyfish.oss-cn-guangzhou.aliyuncs.com/picture/image-20250325221148275.png" alt="image-20250325221148275" style="zoom:50%;" />

​	于是，我们对Relu函数可以这样搞：

​	

<img src="https://whywhyfish.oss-cn-guangzhou.aliyuncs.com/picture/image-20250325221334209.png" alt="image-20250325221334209" style="zoom:50%;" />

#### 					最后的最后，请记住，       节点输出=激活函数（输入的加权和）

#### 	使用 Keras 的代码中的激活函数（Keras实现）

​	有两种基本方法可以实现此目的。首先，我们将导入我们的类。

```python
from keras.models import Sequential
from keras.layers import Dense, Activation
```

现在，指定激活函数的第一种方法是在层的构造函数中，如下所示：

```python
model = Sequential([
    Dense(units=5, input_shape=(3,), activation='relu')
])
```

在本例中，我们有一个层，并且我们将 relu 指定为我们的激活函数 。`Dense``activation='relu'`

第二种方法是在模型实例化后将层和激活函数添加到我们的模型中，如下所示：

```python
model = Sequential()
model.add(Dense(units=5, input_shape=(3,)))
model.add(Activation('relu'))
```

### 第六课：训练人工神经网络

#### 	什么是训练？

​	当我们训练模型时，我们基本上是在尝试解决一个优化问题。我们正在尝试优化模型中的权重。在训练期间，这些权重会迭代更新并趋向最佳值。

#### 	优化算法（最佳化）

​	权重使用我们所谓的优化算法进行优化。优化过程取决于所选的优化算法。

​	目前，运用最多的是**随机梯度下降**

​	**随机梯度下降**的目标是最小化我们称为*损失函数*的某些给定函数，通过不断更新权重，从而不断接近损失函数的最小值。

#### 	损失函数

​	一种常见的损失函数是*均方误差* （MSE）。当然也有其他的损失函数，我们在此不再赘述，当然选什么损失函数，是由我们根据情况判断的。

​	**损失**是网络对图像的预测与图像的真实标签之间的误差或差异

​	**随机梯度下降**最小化此误差，以使我们的模型在预测中尽可能准确。



### 第七课：什么是神经网络学习

​	在上面的笔记中，我们了解了训练过程，并看到用于训练的每个数据点都是通过网络传递的。这种通过网络从输入到输出的传递称为*正向传递*，生成的输出取决于网络内每个连接的权重。

​	一旦数据集中的所有数据点都通过网络，我们就说一个 **epoch（周期）** 完成了。

​	请注意，随着模型的学习，在整个训练过程中会出现许多 epoch。

#### 	那么，我们该怎样学习/训练呢？

​	在初始化模型时，网络权重将设置为任意值。我们还看到，在网络的末端，模型将为给定的输入提供输出。

​	获得输出后，可以通过查看模型预测的内容与真实标签来计算该特定输出的损失（或误差）

#### 	损失函数的梯度

​	计算损失后，将计算此损失函数相对于网络内每个权重的梯度

​	一旦我们有了损失函数的梯度值，我们就可以使用这个值来更新模型的权重。**梯度告诉我们哪个方向会将损失推向最小**，**我们的任务是朝着降低 loss 并逐渐接近此最小值。**

​	记住梯度是会发生更新的。

#### 	学习率

​	总之最重要的是：        **学习率告诉我们应该朝着最小方向迈出多大的一步。**

​	学习率通常介于 0.01 和 0.0001 之间

#### 	更新参数

​	我们将梯度乘以学习率，然后从权重中减去这个乘积，这将得到这个权重的新更新值。

​	<img src="https://whywhyfish.oss-cn-guangzhou.aliyuncs.com/picture/image-20250325230911762.png" alt="image-20250325230911762" style="zoom: 67%;" />

#### 	使用 Keras 进行代码训练

​	让我们从导入所需的类开始：

```python
import keras
from keras.models import Sequential
from keras.layers import Activation
from keras.layers.core import Dense
from keras.optimizers import Adam
from keras.metrics import categorical_crossentropy
```

接下来，我们定义我们的模型：

```python
model = Sequential([
    Dense(units=16, input_shape=(1,), activation='relu'),
    Dense(units=32, activation='relu'),
    Dense(units=2, activation='sigmoid')
])
```

在训练模型之前，我们必须像这样编译它：

```python
model.compile(
    optimizer=Adam(learning_rate=0.0001), 
    loss='sparse_categorical_crossentropy', 
    metrics=['accuracy']
)
```

我们将优化器、损失函数和我们希望看到的指标传递给该函数。请注意，我们指定的优化器称为 *Adam*。 只是 SGD 的一个变体。在构造函数中，我们指定了学习率，在本例中，我们选择了 。`compile()``Adam``Adam``Adam(learning_rate=.0001)``0.0001`

最后，我们将模型与数据进行拟合。将模型拟合到数据意味着在数据上训练模型。我们使用以下代码执行此作：

```python
model.fit(
    x=scaled_train_samples, 
    y=train_labels, 
    batch_size=10, 
    epochs=20, 
    shuffle=True, 
    verbose=2
)
```

`scaled_train_samples`是由训练样本组成的 numpy 数组。

`train_labels`是一个 numpy 数组，由训练样本的相应标签组成。

`batch_size=10`指定一次应向模型发送多少个训练样本。

`epochs=20`表示完整的训练集（所有样本）将总共传递给模型 20 次。

`shuffle=True`表示在将数据传递给模型之前，应先对数据进行 shuffle。

`verbose=2`表示在模型训练时我们将看到多少日志记录。

运行此代码会得到以下输出：

```python
Epoch 1/20 0s - loss: 0.6400 - acc: 0.5576
Epoch 2/20 0s - loss: 0.6061 - acc: 0.6310
Epoch 3/20 0s - loss: 0.5748 - acc: 0.7010
Epoch 4/20 0s - loss: 0.5401 - acc: 0.7633
Epoch 5/20 0s - loss: 0.5050 - acc: 0.7990
Epoch 6/20 0s - loss: 0.4702 - acc: 0.8300
Epoch 7/20 0s - loss: 0.4366 - acc: 0.8495
Epoch 8/20 0s - loss: 0.4066 - acc: 0.8767
Epoch 9/20 0s - loss: 0.3808 - acc: 0.8814
Epoch 10/20 0s - loss: 0.3596 - acc: 0.8962
Epoch 11/20 0s - loss: 0.3420 - acc: 0.9043
Epoch 12/20 0s - loss: 0.3282 - acc: 0.9090
Epoch 13/20 0s - loss: 0.3170 - acc: 0.9129
Epoch 14/20 0s - loss: 0.3081 - acc: 0.9210
Epoch 15/20 0s - loss: 0.3014 - acc: 0.9190
Epoch 16/20 0s - loss: 0.2959 - acc: 0.9205
Epoch 17/20 0s - loss: 0.2916 - acc: 0.9238
Epoch 18/20 0s - loss: 0.2879 - acc: 0.9267
Epoch 19/20 0s - loss: 0.2848 - acc: 0.9252
Epoch 20/20 0s - loss: 0.2824 - acc: 0.9286
```

输出为每个 epoch 提供以下值：

1. 纪元数
2. 持续时间（秒）
3. 损失
4. 准确性

您会注意到，随着 epoch 的进行，损失正在下降，而准确性正在上升。



### 第八课：神经网络中的损失解释

​	根据上节课的知识，损失函数是试图通过迭代更新网络中的权重来最小化的函数。

​	在训练过程中的每个 epoch 结束时，将使用网络的输出预测和相应输入的真实标签来计算损失。

​	**误差=预测值-实际值**

​	接下来，我们熟悉一下最常见的损失函数（MSE）即均方误差

#### 	均分误差（MSE)

​	<img src="https://whywhyfish.oss-cn-guangzhou.aliyuncs.com/picture/image-20250325232025242.png" alt="image-20250325232025242" style="zoom: 67%;" />

#### 	使用 Keras 的代码中的损失函数

​	让我们考虑一下我们在[上一篇文章](https://deeplizard.com/learn/video/_N5kpSMDf4o)中定义的模型：

```python
model = Sequential([
    Dense(16, input_shape=(1,), activation='relu'),
    Dense(32, activation='relu'),
    Dense(2, activation='sigmoid')
])
```

一旦我们有了我们的模型，我们就可以像这样编译它：

```python
model.compile(
    Adam(learning_rate=.0001), 
    loss='sparse_categorical_crossentropy', 
    metrics=['accuracy']
)
```

​	查看调用 的第二个参数 ，我们可以看到指定的 loss 函数 。`compile()``loss='sparse_categorical_crossentropy'`

​	在此示例中，我们使用的是一个名为稀*疏分类交叉熵*的损失函数，但我们可以选择其他几个函数，例如 MSE。

​	[Keras 当前可用的损失函数](https://keras.io/losses/)如下：

* 均方误差
* 平均绝对误差
* 平均绝对百分比误差
* 均方对数误差
* 平方铰链损失
* 铰链损失
* 类别铰链损失
* 对数余弦损失
* 类别交叉熵
* 稀疏类别交叉熵
* 二元交叉熵
* Kullback-Leibler 散度
* 泊松损失
* 余弦相似度损失



### 第九课：神经网络中的学习率解释

#### 	引入学习率

​	我们知道，训练期间的目标是让随机梯度下降最小化训练样本的实际输出和预测输出之间的损失。

​	现在，我们为达到最小损失而采取的这些步骤的大小将取决于学习率。从概念上讲，我们可以将模型的学习率视为*步长*。

​	在训练期间，在计算了输入的损失之后，会根据模型中的每个权重计算该损失的梯度。

​	一旦我们有了这些梯度的值，这就是我们学习率的来源。然后，梯度将乘以学习率。

<img src="https://whywhyfish.oss-cn-guangzhou.aliyuncs.com/picture/image-20250325232820122.png" alt="image-20250325232820122" style="zoom:50%;" />

#### 	更新网络的权重

​	我们得到每个梯度的这个乘积的值乘以学习率，然后我们取这些值中的每一个，并通过从中减去这个值来更新相应的权重。

<img src="https://whywhyfish.oss-cn-guangzhou.aliyuncs.com/picture/image-20250325232958034.png" alt="image-20250325232958034" style="zoom: 50%;" />

​	在选择学习率时，需要小心，他作为一个超参数（自行定义的参数）。在我们确切知道要设置它的具体大小之前，我们需要对这个模型先进行测试和调整，然后把他局限在某一个区域。如[0.01，0.0001]

​	当将学习率设置为此范围较高一侧的数字时，容易步长太大了，容易跑离了我们所期望的最小损失函数的地方。

​	为避免这种情况，我们可以将学习率设置为此范围下限的数字。使用此选项，由于我们的步数非常小，因此我们将需要更长的时间才能达到最小化损失的点。

​	所以我们结合上述情况进行合理讨论。

#### 	Keras 中的学习率

​	这是我们在之前的文章中使用的模型。

```python
model = Sequential([
    Dense(units=16, input_shape=(1,), activation='relu'),
    Dense(units=32, activation='relu', kernel_regularizer=regularizers.l2(0.01)),
    Dense(units=2, activation='sigmoid')
])

model.compile(
    optimizer=Adam(learning_rate=0.0001), 
    loss='sparse_categorical_crossentropy', 
    metrics=['accuracy']
)
```

​	通过我们要编译模型的行，我们可以看到我们指定的第一个参数是我们的优化器。在本例中，我们用作 这个模型。`Adam`

​	现在，对于我们的优化器，我们可以选择通过指定参数来传递我们的学习率。我们可以看到，这里我们指定为学习率。`learning_rate``0.0001`

​	我们提到这个参数是可选的。如果我们没有明确设置它，那么 Keras 分配给这个特定优化器的默认学习率将是 设置。要查看此默认学习率是多少，您需要查看您指定的优化器的 Keras [文档](https://keras.io/optimizers/)。`learning_rate`

​	还有另一种方法可以指定学习率。编译完我们的模型后，我们可以通过设置到我们指定的值来设置学习率。`model.optimizer.learning_rate`

```python
model.optimizer.learning_rate = 0.01
```

​	在这里，我们可以看到我们将其设置为 。现在，如果我们打印学习率的值，我们可以看到它现在已经从 更改为 。`0.01``.0001``.01`

```python
> model.optimizer.learning_rate
0.01
```

### 第十课：训练集、验证集、测试集

​	出于模型的训练和测试目的，我们应该将数据分解为三个不同的数据集。这些数据集将包括以下内容：

- 训练集
- 验证集
- 测试集

#### 	训练集

​	顾名思义，它是用于训练模型的数据集。在每个 epoch 中，我们的模型将一遍又一遍地使用训练集中的相同数据进行训练。

​	但是我们不单希望我们训练出来的模型能搞训练集的内容，也希望能搞其他数据集，能准确预测，于是**验证集**出现。

#### 	验证集

​	验证集是一组独立于训练集的数据集，用于在训练期间验证我们的模型。此验证过程有助于提供可能有助于我们调整超参数的信息。（比如像学习率这些参数等）

​	在训练过程中，模型将对训练集中每个输入的输出进行分类。在此分类发生后，将计算损失，模型中的权重将进行调整。然后，在下一个 epoch 中，它将再次对相同的 input 进行分类。

​	在验证集中，模型同样根据上述步骤进行，它将仅根据它对训练集中正在训练的数据的了解来执行此分类。但是权重不会根据根据我们的验证数据计算的损失在模型中进行更新。

​	不过验证集中的数据与训练集中的数据是不同滴！！！

​	我们需要验证集主要是担心他会**过拟合/欠拟合**。

​	**过拟合**你可以理解为我们的模型变得非常擅长对训练集中的数据进行分类，但它无法对未经过训练的数据进行泛化和准确分类。

​	**欠拟合**你可以理解为我们的模型非常不擅长对训练集中的数据进行分类，所以自然它无法对未经过训练的数据进行泛化和准确分类。

​	如果我们也在验证集上验证模型，并看到它为验证数据提供的结果与它为训练数据提供的结果一样好，那么我们就可以更有信心我们的模型没有过度拟合。

​	但是仅有验证集，并不足以证明他的泛化能力，这时就得有**测试集**

#### 	测试集

​	测试集是一组数据，用于在模型训练后测试模型。测试集与训练集和验证集是分开的。

​	测试集与其他两个测试集之间的一个主要区别是测试集没有标记（你可以理解为没有实际值吧）

​	**在将模型部署到生产环境之前，测试集提供了模型是否泛化良好的最终检查。**

#### 	总结：

<img src="https://whywhyfish.oss-cn-guangzhou.aliyuncs.com/picture/image-20250325235824118.png" alt="image-20250325235824118" style="zoom:50%;" />